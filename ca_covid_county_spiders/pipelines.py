# -*- coding: utf-8 -*-

# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html

from scrapy.exceptions import DropItem
from scrapy.exporters import CsvItemExporter
from ca_covid_county_spiders.utils.covid import dataHasCovid

"""
import boto3
import smart_open
s3 = boto3.resource('s3')
"""



# Default pipeline generated by scrapy.
class CaCovidCountySpidersPipeline(object):
    def process_item(self, item, spider):
        return item



# Custom pipeline written by us!
class CovidContentVerificationPipeline(object):
    def process_item(self, item, spider):
        if not dataHasCovid(item):
            raise DropItem('This content is not related to COVID-19.')
        return item
        


# Another custom pipeline!
class GenerateCsvPerItemPipeline(object):
    def _exporter_for_item(self, item):
        spider = item['spider']
        hash = item['hash']
        f = open('output/{}-{}.csv'.format(spider, hash), 'wb')
        exporter = CsvItemExporter(f, include_headers_line=True)
        exporter.start_exporting()
        return exporter
        
    def process_item(self, item, spider):
        exporter = self._exporter_for_item(item)
        exporter.export_item(item)
        exporter.finish_exporting()
        return item

"""

# Another custom pipeline!
class GenerateCsvPerItemForS3Pipeline(object):
    def _s3_exporter_for_item(self, item):
        spider = item['spider']
        hash = item['hash']
        f = smart_open.open('s3://content-scraper-alpha/{}-{}.csv'.format(spider, hash), 'wb')
        exporter = CsvItemExporter(f, include_headers_line=True)
        exporter.start_exporting()
        return exporter
        
    def process_item(self, item, spider):
        exporter = self._s3_exporter_for_item(item)
        exporter.export_item(item)
        exporter.finish_exporting()
        return item

"""